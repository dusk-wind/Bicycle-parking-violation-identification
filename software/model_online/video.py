import cv2
import time
import numpy as np
from ultralytics import YOLO
import os

def real_time_detection(show_video=True, save_images=True):
    """
    å®æ—¶æ£€æµ‹è§†é¢‘å¹¶æ˜¾ç¤ºç»“æœï¼Œå¯é€‰æ‹©ä¿å­˜ç»“æœå›¾ç‰‡
    Args:
        show_video: æ˜¯å¦å®æ—¶æ˜¾ç¤ºè§†é¢‘
        save_images: æ˜¯å¦ä¿å­˜æ£€æµ‹ç»“æœå›¾ç‰‡
    """
    # æ–‡ä»¶è·¯å¾„
    model_path = r"C:\Users\Acer\Desktop\software\model_online\best_bicycle_violation.pt"
    video_path = r"C:\Users\Acer\Desktop\software\model_online\test.mp4"
    output_dir = r"C:\Users\Acer\Desktop\software\model_online\detection_results"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if save_images and not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"ğŸ“ Created output directory: {output_dir}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ Model file not found: {model_path}")
        return
    
    if not os.path.exists(video_path):
        print(f"âŒ Video file not found: {video_path}")
        return
    
    print("ğŸš€ Loading YOLOv8 model...")
    try:
        model = YOLO(model_path)
        print("âœ… Model loaded successfully")
    except Exception as e:
        print(f"âŒ Model loading failed: {e}")
        return
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ Cannot open video: {video_path}")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"\nğŸ“¹ Video info: {width}x{height}, {fps}FPS, {total_frames} frames")
    if show_video:
        print("ğŸ¬ Starting real-time detection... (Press 'q' to quit, 'space' to pause/resume)")
    else:
        print("ğŸ¬ Starting detection... (Results will be saved as images)")
    if save_images:
        print(f"ğŸ“ Output directory: {output_dir}")
    print("-" * 60)
    
    # ç»Ÿè®¡å˜é‡
    frame_count = 0
    total_detections = 0
    confidence_threshold = 0.6
    save_interval = 30  # æ¯30å¸§ä¿å­˜ä¸€å¼ æ£€æµ‹å›¾ç‰‡
    paused = False
    
    # åˆ›å»ºçª—å£ï¼ˆå¦‚æœéœ€è¦æ˜¾ç¤ºï¼‰
    if show_video:
        cv2.namedWindow('Smart Campus Parking Violation Detection', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Smart Campus Parking Violation Detection', 1200, 800)
    
    try:
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("ğŸ“½ï¸ Video processing completed")
                    break
                
                frame_count += 1
                
                # å¼€å§‹æ£€æµ‹
                start_time = time.time()
                results = model(frame, conf=confidence_threshold, verbose=False)
                inference_time = time.time() - start_time
                
                # å¤åˆ¶å¸§ç”¨äºç»˜åˆ¶
                display_frame = frame.copy()
                
                # å¤„ç†æ£€æµ‹ç»“æœ
                current_detections = 0
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            # è·å–æ£€æµ‹ä¿¡æ¯
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            confidence = box.conf[0].cpu().numpy()
                            
                            if confidence >= confidence_threshold:
                                current_detections += 1
                                total_detections += 1
                                
                                # ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆæ›´åŠ é†’ç›®çš„æ ·å¼ï¼‰
                                cv2.rectangle(display_frame, 
                                            (int(x1), int(y1)), (int(x2), int(y2)), 
                                            (0, 0, 255), 3)  # çº¢è‰²æ¡†
                                
                                # ç»˜åˆ¶èƒŒæ™¯æ¡†ç”¨äºæ–‡å­—
                                label = f"Illegal Parking {confidence:.2f}"
                                (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
                                cv2.rectangle(display_frame, 
                                            (int(x1), int(y1) - label_height - 10), 
                                            (int(x1) + label_width, int(y1)), 
                                            (0, 0, 255), -1)  # çº¢è‰²èƒŒæ™¯
                                
                                # ç»˜åˆ¶ç™½è‰²æ ‡ç­¾æ–‡å­—
                                cv2.putText(display_frame, label,
                                          (int(x1), int(y1) - 5),
                                          cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                                
                                # æ§åˆ¶å°è¾“å‡ºæ£€æµ‹ç»“æœ
                                print(f"ğŸš² Frame {frame_count}: Illegal parking detected, confidence={confidence:.3f}, position=({int(x1)},{int(y1)})-({int(x2)},{int(y2)})")
                
                # æ·»åŠ å®æ—¶ä¿¡æ¯åˆ°å›¾ç‰‡
                info_bg_color = (0, 0, 0)  # é»‘è‰²èƒŒæ™¯
                info_text_color = (255, 255, 255)  # ç™½è‰²æ–‡å­—
                
                # ç»˜åˆ¶ä¿¡æ¯èƒŒæ™¯ï¼ˆæ›´å°çš„å°ºå¯¸ï¼‰
                cv2.rectangle(display_frame, (5, 5), (280, 110), info_bg_color, -1)
                
                fps_text = f"FPS: {1/inference_time:.1f}"
                frame_text = f"Frame: {frame_count}/{total_frames}"
                detection_text = f"Current: {current_detections}"
                total_text = f"Total: {total_detections}"
                progress_text = f"Progress: {(frame_count/total_frames)*100:.1f}%"
                
                # ä½¿ç”¨æ›´å°çš„å­—ä½“å’Œæ›´ç´§å¯†çš„è¡Œé—´è·
                cv2.putText(display_frame, fps_text, (10, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.5, info_text_color, 1)
                cv2.putText(display_frame, frame_text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, info_text_color, 1)
                cv2.putText(display_frame, detection_text, (10, 58), cv2.FONT_HERSHEY_SIMPLEX, 0.5, info_text_color, 1)
                cv2.putText(display_frame, total_text, (10, 76), cv2.FONT_HERSHEY_SIMPLEX, 0.5, info_text_color, 1)
                cv2.putText(display_frame, progress_text, (10, 94), cv2.FONT_HERSHEY_SIMPLEX, 0.5, info_text_color, 1)
                
                # ä¿å­˜æ£€æµ‹ç»“æœå›¾ç‰‡ï¼ˆæ¯éš”ä¸€å®šå¸§æ•°æˆ–æœ‰æ£€æµ‹æ—¶ä¿å­˜ï¼‰
                if save_images and (current_detections > 0 or frame_count % save_interval == 0):
                    output_path = os.path.join(output_dir, f"frame_{frame_count:06d}_detected_{current_detections}.jpg")
                    cv2.imwrite(output_path, display_frame)
                    if current_detections > 0:
                        print(f"ğŸ’¾ Saved detection image: frame_{frame_count:06d}_detected_{current_detections}.jpg")
                
                # æ§åˆ¶å°è¾“å‡ºè¿›åº¦ï¼ˆæ¯60å¸§è¾“å‡ºä¸€æ¬¡ï¼‰
                if frame_count % 60 == 0:
                    progress = (frame_count / total_frames) * 100
                    avg_fps = 1 / inference_time
                    print(f"ğŸ“Š Progress: {progress:.1f}% | Avg FPS: {avg_fps:.1f} | Total detections: {total_detections}")
            
            # æ˜¾ç¤ºè§†é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if show_video:
                cv2.imshow('Smart Campus Parking Violation Detection', display_frame)
                
                # é”®ç›˜æ§åˆ¶
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):  # æŒ‰'q'é€€å‡º
                    print("\nâ¹ï¸ User quit detection")
                    break
                elif key == ord(' '):  # æŒ‰ç©ºæ ¼æš‚åœ/ç»§ç»­
                    paused = not paused
                    print(f"â¸ï¸ {'Paused' if paused else 'Resumed'} playback")
            else:
                # å¦‚æœä¸æ˜¾ç¤ºè§†é¢‘ï¼Œç¨å¾®å»¶è¿Ÿé¿å…CPUå ç”¨è¿‡é«˜
                time.sleep(0.01)
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Detection interrupted")
    
    finally:
        # é‡Šæ”¾èµ„æº
        cap.release()
        if show_video:
            cv2.destroyAllWindows()
        
        # æœ€ç»ˆç»Ÿè®¡
        print("\n" + "="*60)
        print("ğŸ“ˆ Detection Statistics Report:")
        print(f"   Total frames processed: {frame_count}")
        print(f"   Total detections: {total_detections}")
        if frame_count > 0:
            print(f"   Average detection rate: {total_detections/frame_count:.2f} per frame")
        print(f"   Video completion: {frame_count/total_frames*100:.1f}%")
        if save_images:
            print(f"   Detection images saved to: {output_dir}")
        print("âœ… Detection completed")
        
        # åˆ—å‡ºä¿å­˜çš„å›¾ç‰‡ï¼ˆå¦‚æœå¯ç”¨ä¿å­˜ï¼‰
        if save_images and os.path.exists(output_dir):
            saved_images = [f for f in os.listdir(output_dir) if f.endswith('.jpg')]
            print(f"ğŸ“¸ Total {len(saved_images)} detection images saved")

def main():
    print("ğŸš² Smart Campus Parking Violation Detection System")
    print("=" * 50)
    print("Choose running mode:")
    print("1. Real-time display + Save images (Recommended)")
    print("2. Real-time display only")
    print("3. Save images only")
    
    try:
        choice = input("Please enter your choice (1-3, default 1): ").strip()
        if choice == "2":
            real_time_detection(show_video=True, save_images=False)
        elif choice == "3":
            real_time_detection(show_video=False, save_images=True)
        else:  # é»˜è®¤é€‰æ‹©1
            real_time_detection(show_video=True, save_images=True)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Program exited")

if __name__ == "__main__":
    main()
